llm_model: "microsoft/bitnet-b1.58-2B-4T"
retriever_type: "smart"
generator_type: "llm"
max_tokens: 250
data_path: "data/documents/"
temperature: 0.7
max_gpu_memory: "3.8GB" # aprox 95% of 4GB GPU

# Smart Retriever configuration
retrieval:
  model_name: "all-MiniLM-L6-v2"
  top_k: 3
  embeddings_path: "data/embeddings"
  
  # Enable/disable components
  use_reranking: true
  use_cache: true
  use_filters: true
  use_metrics: true
  
  # Component configurations
  reranker_model: "cross-encoder/ms-marco-MiniLM-L12-v2"
  rerank_top_k: 10
  cache_ttl_hours: 24
  min_score_threshold: 0.3

  faiss:
    dimension: 384 # Ensure this matches your embedding model output dimension
    metric: "inner_product"  # Options: "inner_product", "l2"

# Logging configuration
logging:
  level: INFO
  log_to_file: true
  log_file: "logs/rag.log"
  format: "%(asctime)s [%(levelname)s] %(name)s: %(message)s"